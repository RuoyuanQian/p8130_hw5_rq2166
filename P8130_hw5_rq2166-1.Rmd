---
title: "p8130_hw5_rq2166"
author: "Ruoyuan Qian"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(faraway)
library(tidyverse)
library(dplyr)
library(arsenal)
library(ggplot2)
library(ggpubr)
library(leaps)
library(Rmisc)
library(faraway)
library(broom)
library(boot)
library(caret)
library(MPV)
data(state.x77)
```

# Problem 1 

## a)
```{r}
state.x77 = 
  state.x77 %>% 
  as.data.frame() %>% 
  janitor::clean_names()



 sum_data  <-  arsenal::tableby( ~ ., 
                                data  = state.x77,
                                test  = FALSE, 
                                total = FALSE,
                                numeric.stats =
                                  c("meansd","medianq1q3","range"))
summ = summary(sum_data,text = TRUE)
summ


```

## b)

```{r}

ggh_p = 
state.x77 %>% 
 ggplot(aes(population,..density..))+
 geom_histogram()+
 geom_line(stat = 'density',size = 1)+
    labs(x = "population")

ggh_in = 
state.x77 %>% 
 ggplot(aes(income,..density..))+
 geom_histogram()+
 geom_line(stat = 'density',size = 1)+
    labs(x = "income")

ggh_il = 
state.x77 %>% 
 ggplot(aes(illiteracy,..density..))+
 geom_histogram()+
 geom_line(stat = 'density',size = 1)+
    labs(x = "illiteracy")

ggh_m = 
state.x77 %>% 
 ggplot(aes(murder,..density..))+
 geom_histogram()+
 geom_line(stat = 'density',size = 1)+
    labs(x = "murder")

ggh_h = 
state.x77 %>% 
 ggplot(aes(hs_grad,..density..))+
 geom_histogram()+
 geom_line(stat = 'density',size = 1)+
    labs(x = "hs_grad")

ggh_f = 
state.x77 %>% 
 ggplot(aes(frost,..density..))+
 geom_histogram()+
 geom_line(stat = 'density',size = 1)+
    labs(x = "frost")

ggh_a = 
state.x77 %>% 
 ggplot(aes(area,..density..))+
 geom_histogram()+
 geom_line(stat = 'density',size = 1)+
    labs(x = "area")

ggh_li = 
state.x77 %>% 
 ggplot(aes(life_exp,..density..))+
 geom_histogram()+
 geom_line(stat = 'density',size = 1)+
    labs(x = "life_exp")

multiplot(ggh_p,ggh_in,ggh_il,
          ggh_m,ggh_h,ggh_f,ggh_a,ggh_li,
          cols=2) 
```

transformation
```{r}
ggl_p = 
state.x77 %>% 
  mutate(population = log(population)) %>% 
 ggplot(aes(population,..density..))+
 geom_histogram()+
 geom_line(stat = 'density',size = 1)+
    labs(x = "population")

ggl_a = 
state.x77 %>% 
  mutate(area = log(area)) %>% 
 ggplot(aes(area,..density..))+
 geom_histogram()+
 geom_line(stat = 'density',size = 1)+
    labs(x = "area")


multiplot(ggl_p,ggl_a,
          cols=2) 

```

```{r}
state_log = 
state.x77 %>% 
  mutate(log_area = log(area),
         log_population = log(population))%>%  
  select(-area,-population)
```

## c)

### i

backwards
```{r}

# Same thing
mult.fit <- lm(life_exp ~ ., data=state_log)
summary(mult.fit)

step1<-update(mult.fit, . ~ . -income)
summary(step1)

# No Alcmod
step2<-update(step1, . ~ . -illiteracy)
summary(step2)

# No Age
step3<-update(step2, . ~ . -log_area)
summary(step3)


```

forwards
```{r}
### Step 1:  Fit simple linear regressions for all variables,look for the variable with lowest p-value
fit1 <- lm(life_exp ~ income, data=state_log)
tidy(fit1)
fit2 <- lm(life_exp ~ illiteracy, data=state_log)
tidy(fit2)
fit3 <- lm(life_exp ~ murder, data=state_log)
tidy(fit3)
fit4 <- lm(life_exp ~ hs_grad, data=state_log)
tidy(fit4)
fit5 <- lm(life_exp ~ frost, data=state_log)
tidy(fit5)
fit6 <- lm(life_exp ~ log_area, data=state_log)
tidy(fit6)
fit7 <- lm(life_exp ~ log_population, data=state_log)
tidy(fit7)

forward1<-lm(life_exp~murder, data=state_log)
tidy(forward1)

### Step 2: Enter the one with the lowest p-value in the rest 
fit1 <- update(forward1, . ~ . +income)
tidy(fit1)
fit2 <- update(forward1, . ~ . +illiteracy)
tidy(fit2)
fit3 <- update(forward1, . ~ . +hs_grad)
tidy(fit3)
fit4 <- update(forward1, . ~ . +frost)
tidy(fit4)
fit5 <- update(forward1, . ~ . +log_area)
tidy(fit5)
fit6 <- update(forward1, . ~ . +log_population)
tidy(fit6)

# Enter the one with the lowest p-value: Progindex
forward2 <- update(forward1, . ~ . + hs_grad)
tidy(forward2)

### Step 3: Enter the one with the lowest p-value in the rest 
fit1 <- update(forward2, . ~ . +income)
tidy(fit1)
fit2 <- update(forward2, . ~ . +illiteracy)
tidy(fit2)
fit3 <- update(forward2, . ~ . +frost)
tidy(fit3)
fit4 <- update(forward2, . ~ . +log_area)
tidy(fit4)
fit5 <- update(forward2, . ~ . +log_population)
tidy(fit5)

# Enter the one with the lowest p-value: Alcheav
forward3 <- update(forward2, . ~ . + log_population)
tidy(forward3)

### Step 4: Enter the one with the lowest p-value in the rest 
fit1 <- update(forward3, . ~ . +income)
tidy(fit1)
fit2 <- update(forward3, . ~ . +illiteracy)
tidy(fit2)
fit3 <- update(forward3, . ~ . +frost)
tidy(fit3)
fit4 <- update(forward3, . ~ . +log_area)
tidy(fit4)

# Enter the one with the lowest p-value: Bloodclot
forward4 <- update(forward3, . ~ . + frost)
tidy(forward4)


### Step 5: Enter the one with the lowest p-value in the rest 
fit1 <- update(forward4, . ~ . +income)
tidy(fit1)
fit2 <- update(forward4, . ~ . +illiteracy)
tidy(fit2)
fit3 <- update(forward4, . ~ . +log_area)
tidy(fit3)


# The model we obtained is Lnsurvival ~ Enzyme + Progindex + Alcheav + Bloodclot
for.fit <- lm(life_exp ~ murder + hs_grad + log_population + frost,state_log)
summary(for.fit)
```

stepwise
```{r}
mult.fit <- lm(life_exp ~ ., data=state_log)
step(mult.fit, direction='backward')
```


### ii

`frost` is 0.042779, slightly less than 0.05, I decided to keep it since according to all of the three models,  they all contain the `frost`. Furthermore, the `AIC` is the smallest when select the `frost` into the model.

```{r}
for.fit <- lm(life_exp ~ murder + hs_grad + log_population + frost,state_log)

for.fit1 <- lm(life_exp ~ murder + hs_grad + log_population, state_log)

anova(for.fit1,for.fit)

```


### iii

```{r}
cor(state_log)
```

The correlation between two is -0.657, so there is some association between them but not very strong.

## d)

```{r}
# Printing the 2 best models of each size, using the Cp criterion:
leaps(x = state_log[,-3], y = state_log[,3], nbest=2, method="Cp")


# Printing the 2 best models of each size, using the adjusted R^2 criterion:
leaps(x = state_log[,-3], y = state_log[,3], nbest=2, method="adjr2")

# Summary of models for each size (one model per size)
# Function regsubsets() performs a subset slection by identifying the "best" model that contains
# a certain number of predictors. By default "best" is chosen using SSE/RSS (smaller is better).


b<-regsubsets(life_exp ~ ., data=state_log)
   (rs<-summary(b))

# This function also returns R2, Cp, BIC for each "best" model.
# Let's take a look at these values.

# Plots of Cp and Adj-R2 as functions of parameters

par(mar=c(4,4,1,1))
par(mfrow=c(1,2))

plot(2:8, rs$cp, xlab="No of parameters", ylab="Cp Statistic")
abline(0,1)

plot(2:8, rs$adjr2, xlab="No of parameters", ylab="Adj R2")


```


```{r}
# AIC of the 3-predictor model:

aic.fit3 <- lm(life_exp ~ murder + hs_grad + log_population,state_log )
summary(aic.fit3)
AIC(aic.fit3)

aic.fit4 <- lm(life_exp ~ murder + hs_grad + log_population + frost ,state_log )
summary(aic.fit4)
AIC(aic.fit4)

aic.fit5 <- lm(life_exp ~ murder + hs_grad + log_population + frost +log_area ,state_log )
summary(aic.fit5)
AIC(aic.fit5)
```


## e)

### i

```{r}
aic.fit4 <- lm(life_exp ~ murder + hs_grad + log_population + frost ,state_log[-11,] )
summary(aic.fit4)
```


### ii
```{r}

par(mfrow=c(2,2))
plot(aic.fit4)

```

### iii

```{r}

# Use 5-fold validation and create the training sets

set.seed(1)
data_train<-trainControl(method="cv", number=10)

# Fit the 4-variables model that we discussed in previous lectures
model_caret<-train(life_exp ~ murder + hs_grad + log_population + frost,
                   data=state_log[-11,],
                   trControl=data_train,
                   method='lm',
                   na.action=na.pass)
  
# Model predictions using 4 parts of the data for training 
model_caret


# Model coefficients
model_caret$finalModel

# Examine model prediction for each fold
model_caret$resample

# Look at standard deviation around the Rsquared value by examining the R-squared from each fold.
sd(model_caret$resample$Rsquared)

```


# Porblem 2

```{r}
CP = read_csv(".\\data\\CommercialProperties.csv") 

```


## a)

```{r}
mult.fit <- lm(Rental_rate ~ ., data=CP)
summary(mult.fit)
```


## b)

```{r}

gg_a = 
    CP %>% 
    ggplot(aes(x = Age, y = Rental_rate))+
    geom_point()+
     labs(x = "Age")
  
  
gg_t = 
    CP %>% 
    ggplot(aes(x = Taxes, y = Rental_rate))+
    geom_point()+
     labs(x = "Taxes")
  
  
gg_s = 
    CP %>% 
    ggplot(aes(x = Sq_footage, y = Rental_rate))+
    geom_point()+
     labs(x = "Sq_footage")
  


multiplot(gg_a,gg_t,gg_s,
          cols=2)  
```


## c)

```{r}
mult.fit <- lm(Rental_rate ~ Age + Taxes + Sq_footage, data=CP)
summary(mult.fit)
```

## d)

### i
```{r}
CP_center = 
CP %>% 
  mutate(Age_center = Age - mean(Age)) 
mult.fit <- lm(Rental_rate ~ Age_center + Taxes + Sq_footage + I(Age_center^2), data=CP_center)
summary(mult.fit)


mult.fit1 <- lm(Rental_rate ~ Age + Taxes + Sq_footage + I(Age^2), data=CP)
summary(mult.fit1)


```

### ii

```{r}

CP$Ageest <- ifelse(CP$Age<8, 0, CP$Age-8)
#check<- cbind(data_hosp$NURSE,data_hosp$NURSEstar)

reg_spline<-lm(Rental_rate ~ Age + Taxes + Sq_footage + Ageest, data=CP)
summary(reg_spline)

reg_spline1<-lm(Rental_rate ~ Age + Ageest, data=CP)
summary(reg_spline1)

mutate(CP, fitted = fitted(reg_spline1)) %>%
  ggplot(., aes(y=Rental_rate, x=Age)) + geom_point() + 
  geom_line(aes(y = fitted), color = "red") + theme_bw()

reg_spline1<-lm(Rental_rate ~ Age + Ageest  + Taxes + Sq_footage, data=CP)
summary(reg_spline1)

```


## e)

```{r}
mult.fit1 <- lm(Rental_rate ~ Age + Taxes + Sq_footage, data=CP)
mult.fit2 <- lm(Rental_rate ~ Age_center + Taxes + Sq_footage + I(Age_center^2), data=CP_center)
anova(mult.fit1,mult.fit2)
```

